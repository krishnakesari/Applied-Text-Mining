{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "*** Introductory Examples for the NLTK Book ***\nLoading text1, ..., text9 and sent1, ..., sent9\nType the name of the text or sentence to view it.\nType: 'texts()' or 'sents()' to list the materials.\ntext1: Moby Dick by Herman Melville 1851\ntext2: Sense and Sensibility by Jane Austen 1811\ntext3: The Book of Genesis\ntext4: Inaugural Address Corpus\ntext5: Chat Corpus\ntext6: Monty Python and the Holy Grail\ntext7: Wall Street Journal\ntext8: Personals Corpus\ntext9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
    }
   ],
   "source": [
    "## Basic NLP tasks with NLTK\n",
    "import nltk\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Conn',\n 'necessities',\n 'Associates',\n 'meatpacking',\n 'conference',\n 'owning',\n 'AIDS',\n 'Buyers',\n 'nonexecutive',\n 'federal']"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "text7\n",
    "sent7\n",
    "len(sent7) # Number of sentenses\n",
    "len(text7) # Number of words\n",
    "len(set(text7)) # number of unique words\n",
    "list(set(text7))[:10] # First ten of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "12408"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "## Frequency of words\n",
    "dist = FreqDist(text7)\n",
    "len(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Pierre', 'Vinken', ',', '61', 'years', 'old', 'will', 'join', 'the', 'board']"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "vocab1 = dist.keys() # Frequency distribution of words- count of number of times\n",
    "list(vocab1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "20"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "dist['four']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['billion',\n 'company',\n 'president',\n 'because',\n 'market',\n 'million',\n 'shares',\n 'trading',\n 'program']"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "freqwords = [w for w in vocab1 if len(w)>5 and dist[w] > 100]\n",
    "freqwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['list', 'listed', 'lists', 'listing', 'listings']"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Normalizing and Stemming\n",
    "input1 = \"List listed lists listing listings\"\n",
    "words1 = input1.lower().split(' ')\n",
    "words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['list', 'list', 'list', 'list', 'list']"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "porter = nltk.PorterStemmer()  # Stemming\n",
    "[porter.stem(t) for t in words1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Universal',\n 'Declaration',\n 'of',\n 'Human',\n 'Rights',\n 'Preamble',\n 'Whereas',\n 'recognition',\n 'of',\n 'the',\n 'inherent',\n 'dignity',\n 'and',\n 'of',\n 'the',\n 'equal',\n 'and',\n 'inalienable',\n 'rights',\n 'of']"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# Lemmatization\n",
    "udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "udhr[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['univers',\n 'declar',\n 'of',\n 'human',\n 'right',\n 'preambl',\n 'wherea',\n 'recognit',\n 'of',\n 'the',\n 'inher',\n 'digniti',\n 'and',\n 'of',\n 'the',\n 'equal',\n 'and',\n 'inalien',\n 'right',\n 'of']"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "[porter.stem(t) for t in udhr[:20]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Universal',\n 'Declaration',\n 'of',\n 'Human',\n 'Rights',\n 'Preamble',\n 'Whereas',\n 'recognition',\n 'of',\n 'the',\n 'inherent',\n 'dignity',\n 'and',\n 'of',\n 'the',\n 'equal',\n 'and',\n 'inalienable',\n 'right',\n 'of']"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "[WNlemma.lemmatize(t) for t in udhr[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Children', \"shouldn't\", 'drink', 'a', 'sugary', 'drink', 'before', 'bed.']"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# Tokenization\n",
    "text11 = \"Children shouldn't drink a sugary drink before bed.\"\n",
    "text11.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Children',\n 'should',\n \"n't\",\n 'drink',\n 'a',\n 'sugary',\n 'drink',\n 'before',\n 'bed',\n '.']"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "nltk.word_tokenize(text11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "4"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "text12 = \"This is the first sentence. A gallon of milk in the U.S. costs $2.99. Is this the third sentence? Yes, it is!\"\n",
    "sentences = nltk.sent_tokenize(text12)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['This is the first sentence.',\n 'A gallon of milk in the U.S. costs $2.99.',\n 'Is this the third sentence?',\n 'Yes, it is!']"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MD: modal auxiliary\n    can cannot could couldn't dare may might must need ought shall should\n    shouldn't will would\n"
    }
   ],
   "source": [
    "# Advanced NLP tasks with NLTK\n",
    "## POS Tagging\n",
    "nltk.help.upenn_tagset('MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('Children', 'NNP'),\n ('should', 'MD'),\n (\"n't\", 'RB'),\n ('drink', 'VB'),\n ('a', 'DT'),\n ('sugary', 'JJ'),\n ('drink', 'NN'),\n ('before', 'IN'),\n ('bed', 'NN'),\n ('.', '.')]"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "text13 = nltk.word_tokenize(text11)\n",
    "nltk.pos_tag(text13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('Visiting', 'VBG'),\n ('aunts', 'NNS'),\n ('can', 'MD'),\n ('be', 'VB'),\n ('a', 'DT'),\n ('nuisance', 'NN')]"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "text14 = nltk.word_tokenize(\"Visiting aunts can be a nuisance\")\n",
    "nltk.pos_tag(text14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S (NP Alice) (VP (V loves) (NP Bob)))\n"
    }
   ],
   "source": [
    "## Parsing sentence structure\n",
    "text15 = nltk.word_tokenize(\"Alice loves Bob\")\n",
    "grammer = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP\n",
    "NP -> 'Alice' | 'Bob'\n",
    "V -> 'loves'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammer)\n",
    "trees = parser.parse_all(text15)\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<Grammar with 13 productions>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "text16 = nltk.word_tokenize(\"I saw the man with a telescope\")\n",
    "grammer1 = nltk.data.load(\"mygrammer.cfg\")\n",
    "grammer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S\n  (NP I)\n  (VP\n    (VP (V saw) (NP (Det the) (N man)))\n    (PP (P with) (NP (Det a) (N telescope)))))\n(S\n  (NP I)\n  (VP\n    (V saw)\n    (NP (Det the) (N man) (PP (P with) (NP (Det a) (N telescope))))))\n"
    }
   ],
   "source": [
    "parser = nltk.ChartParser(grammer1)\n",
    "trees = parser.parse_all(text16)\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S\n  (NP-SBJ\n    (NP (NNP Pierre) (NNP Vinken))\n    (, ,)\n    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n    (, ,))\n  (VP\n    (MD will)\n    (VP\n      (VB join)\n      (NP (DT the) (NN board))\n      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n      (NP-TMP (NNP Nov.) (CD 29))))\n  (. .))\n"
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "text17 = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    "print(text17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('The', 'DT'), ('old', 'JJ'), ('man', 'NN'), ('the', 'DT'), ('boat', 'NN')]"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# POS tagging and parsing ambiguity\n",
    "text18 = nltk.word_tokenize(\"The old man the boat\")\n",
    "nltk.pos_tag(text18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('colorless', 'NN'),\n ('green', 'JJ'),\n ('ideas', 'NNS'),\n ('sleep', 'VBP'),\n ('furiously', 'RB')]"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "text19 = nltk.word_tokenize(\"colorless green ideas sleep furiously\")\n",
    "nltk.pos_tag(text19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit5c21451e1d864d53a27be528a149d476",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}